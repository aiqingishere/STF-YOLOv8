import torch
import torch.nn as nn
import torch.nn.functional as F

class TextResidualFusion(torch.nn.Module):
    def __init__(self, text_dim, feat_dim, scale=1.0):
        super().__init__()
        self.text_proj = torch.nn.Linear(text_dim, feat_dim)  # âš¡ ä¿è¯è¾“å‡ºé€šé“=featé€šé“
        self.scale = scale

    def forward(self, feat, text_feat):
        if text_feat is None:
            return feat

        # âš¡ device ä¿è¯
        text_feat = text_feat.to(feat.device)

        # æ˜ å°„åˆ° feat é€šé“
        t = self.text_proj(text_feat)  # [B, feat_dim]
        gamma = torch.sigmoid(t).view(t.shape[0], t.shape[1], 1, 1)  # [B, C, 1, 1]
        out = feat + self.scale * gamma * feat

        print(f"ğŸ”¥ TextResidualFusion called: feat {feat.shape}, text_feat {text_feat.shape}, gamma {gamma.shape}")
        return out
